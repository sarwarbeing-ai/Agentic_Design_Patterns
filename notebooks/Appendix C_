{"cells":[{"cell_type":"code","source":["# A simple LCEL chain conceptually\n","# (This is not runnable code, just illustrates the flow)\n","\n","chain = prompt | model | output_parser"],"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'prompt' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2-827425956.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# (This is not runnable code, just illustrates the flow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0moutput_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'prompt' is not defined"]}],"execution_count":2,"metadata":{"id":"NhfdOggSqMrH","colab":{"base_uri":"https://localhost:8080/","height":180},"executionInfo":{"status":"error","timestamp":1751433010748,"user_tz":-120,"elapsed":38,"user":{"displayName":"Antonio Gulli","userId":"17769953396342459304"}},"outputId":"b9dff763-9cf1-42fa-c793-f731632f3eae"}},{"cell_type":"code","source":["# Graph state\n","class State(TypedDict):\n","    topic: str\n","    joke: str\n","    story: str\n","    poem: str\n","    combined_output: str\n","\n","\n","# Nodes\n","def call_llm_1(state: State):\n","    \"\"\"First LLM call to generate initial joke\"\"\"\n","\n","    msg = llm.invoke(f\"Write a joke about {state['topic']}\")\n","    return {\"joke\": msg.content}\n","\n","\n","def call_llm_2(state: State):\n","    \"\"\"Second LLM call to generate story\"\"\"\n","\n","    msg = llm.invoke(f\"Write a story about {state['topic']}\")\n","    return {\"story\": msg.content}\n","\n","\n","def call_llm_3(state: State):\n","    \"\"\"Third LLM call to generate poem\"\"\"\n","\n","    msg = llm.invoke(f\"Write a poem about {state['topic']}\")\n","    return {\"poem\": msg.content}\n","\n","\n","def aggregator(state: State):\n","    \"\"\"Combine the joke and story into a single output\"\"\"\n","\n","    combined = f\"Here's a story, joke, and poem about {state['topic']}!\\n\\n\"\n","    combined += f\"STORY:\\n{state['story']}\\n\\n\"\n","    combined += f\"JOKE:\\n{state['joke']}\\n\\n\"\n","    combined += f\"POEM:\\n{state['poem']}\"\n","    return {\"combined_output\": combined}\n","\n","\n","# Build workflow\n","parallel_builder = StateGraph(State)\n","\n","# Add nodes\n","parallel_builder.add_node(\"call_llm_1\", call_llm_1)\n","parallel_builder.add_node(\"call_llm_2\", call_llm_2)\n","parallel_builder.add_node(\"call_llm_3\", call_llm_3)\n","parallel_builder.add_node(\"aggregator\", aggregator)\n","\n","# Add edges to connect nodes\n","parallel_builder.add_edge(START, \"call_llm_1\")\n","parallel_builder.add_edge(START, \"call_llm_2\")\n","parallel_builder.add_edge(START, \"call_llm_3\")\n","parallel_builder.add_edge(\"call_llm_1\", \"aggregator\")\n","parallel_builder.add_edge(\"call_llm_2\", \"aggregator\")\n","parallel_builder.add_edge(\"call_llm_3\", \"aggregator\")\n","parallel_builder.add_edge(\"aggregator\", END)\n","parallel_workflow = parallel_builder.compile()\n","\n","# Show workflow\n","display(Image(parallel_workflow.get_graph().draw_mermaid_png()))\n","\n","# Invoke\n","state = parallel_workflow.invoke({\"topic\": \"cats\"})\n","print(state[\"combined_output\"])"],"metadata":{"id":"RCQ5d2idgitI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.adk.agents import LlmAgent\n","from google.adk.tools import google_Search\n","\n","dice_agent = LlmAgent(\n","    model=\"gemini-2.0-flash-exp\",\n","    name=\"question_answer_agent\",\n","    description=\"A helpful assistant agent that can answer questions.\",\n","    instruction=\"\"\"Respond to the query using google search\"\"\",\n","    tools=[google_search],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"vaHmwKWLmzgW","executionInfo":{"status":"error","timestamp":1751434280137,"user_tz":-120,"elapsed":13,"user":{"displayName":"Antonio Gulli","userId":"17769953396342459304"}},"outputId":"ddd8ea58-432a-488c-ad58-5540e186a4b0"},"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'ParallelAgent' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4-1246429252.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mParallelAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_agents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mResearcherAgent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResearcherAgent2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResearcherAgent3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'ParallelAgent' is not defined"]}]},{"cell_type":"code","source":["@crew\n","def crew(self) -> Crew:\n","    \"\"\"Creates the research crew\"\"\"\n","    return Crew(\n","      agents=self.agents,\n","      tasks=self.tasks,\n","      process=Process.sequential,\n","      verbose=True,\n","    )"],"metadata":{"id":"bpbk9C66njvd"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"15XCzDOvBhIQaZ__xkvruf5sP9OznAbK9","timestamp":1749895601577}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}