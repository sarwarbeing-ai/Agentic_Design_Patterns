{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3d9NNmd8b7VzMsCuUIVdG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QMUWyDSjx-VH"},"outputs":[],"source":["import os\n","import logging\n","import time\n","import json\n","import re\n","from functools import wraps\n","from typing import Tuple, Any\n","\n","from crewai import Agent, Task, Crew, Process\n","from crewai_tools import SerperDevTool\n","from pydantic import BaseModel, Field, ValidationError\n","\n","# --- 0. Setup ---\n","# Set up logging for observability\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","# For demonstration, we'll assume these are set in your environment\n","# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\"\n","# os.environ[\"SERPER_API_KEY\"] = \"YOUR_SERPER_API_KEY\"\n","\n","\n","# --- 1. Input Validation (Improved) ---\n","def moderate_input(text: str) -> Tuple[bool, str]:\n","    \"\"\"\n","    Simulates content moderation using whole-word matching to avoid false positives.\n","    \"\"\"\n","    # REFACTORED: Use regex for whole-word matching to prevent flagging words\n","    # like \"non-violent\".\n","    forbidden_keywords = [\"violence\", \"hate\", \"illegal\"]\n","    pattern = r'\\b(' + '|'.join(re.escape(k) for k in forbidden_keywords) + r')\\b'\n","\n","    if re.search(pattern, text, re.IGNORECASE):\n","        return False, f\"Input contains forbidden content based on keyword matching.\"\n","    return True, \"Input is clean.\"\n","\n","\n","# --- 2. Structured Output Definition ---\n","class ResearchSummary(BaseModel):\n","    \"\"\"Pydantic model for structured research output.\"\"\"\n","    title: str = Field(description=\"A concise title for the research summary.\")\n","    key_findings: list[str] = Field(description=\"A list of 3-5 key findings.\")\n","    confidence_score: float = Field(description=\"A score from 0.0 to 1.0 indicating confidence in the findings.\")\n","\n","\n","# --- 3. Output Validation Guardrail (Corrected) ---\n","def validate_research_summary(output: str) -> Tuple[bool, Any]:\n","    \"\"\"\n","    Validates the raw string output from the LLM.\n","    The guardrail receives a string, which must be parsed and validated against the Pydantic model.\n","    \"\"\"\n","    try:\n","        # Attempt to parse the LLM's string output into a JSON object.\n","        data = json.loads(output)\n","        # Validate the data against the ResearchSummary model.\n","        summary = ResearchSummary.model_validate(data)\n","\n","        # Perform logical checks on the validated data.\n","        if not summary.title or len(summary.title.strip()) < 5:\n","            return False, \"Research summary title is too short or empty.\"\n","        if len(summary.key_findings) < 3:\n","            return False, \"Research summary must have at least 3 key findings.\"\n","        if not (0.0 <= summary.confidence_score <= 1.0):\n","            return False, \"Confidence score must be between 0.0 and 1.0.\"\n","\n","        logging.info(f\"Guardrail PASSED for: {summary.title}\")\n","        # IMPORTANT: If valid, return True and the original, approved string.\n","        return True, output\n","\n","    except (json.JSONDecodeError, ValidationError) as e:\n","        # If the output is not valid JSON or doesn't match the model, reject it.\n","        logging.error(f\"Guardrail FAILED: {e}\")\n","        return False, f\"Output failed validation: {e}\"\n","\n","\n","# --- 4. Error Handling and Resilience ---\n","def retry_with_exponential_backoff(max_retries: int = 3, initial_delay: float = 1.0):\n","    \"\"\"\n","    A decorator to retry a function with exponential backoff.\n","    NOTE: For production, consider a robust library like `tenacity`.\n","    \"\"\"\n","    def decorator(func):\n","        @wraps(func)\n","        def wrapper(*args, **kwargs):\n","            delay = initial_delay\n","            for i in range(max_retries):\n","                try:\n","                    return func(*args, **kwargs)\n","                except Exception as e:\n","                    logging.warning(f\"Attempt {i+1}/{max_retries} failed: {e}. Retrying in {delay:.2f} seconds...\")\n","                    time.sleep(delay)\n","                    delay *= 2\n","            raise Exception(f\"Function {func.__name__} failed after {max_retries} attempts.\")\n","        return wrapper\n","    return decorator\n","\n","\n","# --- 5. Agent and Task Setup ---\n","search_tool = SerperDevTool()\n","\n","# Agent 1: Researcher\n","researcher = Agent(\n","    role='Senior Research Analyst',\n","    goal='Provide concise and accurate research summaries based on web searches.',\n","    backstory='An expert in extracting key insights from vast amounts of information.',\n","    tools=[search_tool],\n","    verbose=True,\n","    allow_delegation=False,\n",")\n","\n","# Agent 2: Data Analyst (with restricted tools)\n","data_analyst = Agent(\n","    role='Data Analyst',\n","    goal='Process and clean structured data.',\n","    backstory='Meticulous in handling datasets and ensuring data integrity.',\n","    tools=[], # This agent has NO tools that could access external systems.\n","    verbose=True\n",")\n","\n","# Task 1: Research Task with validation\n","research_task = Task(\n","    description=(\n","        \"Conduct thorough research on 'climate change impacts on coastal cities'. \"\n","        \"Synthesize the findings into a JSON object containing a title, a list of \"\n","        \"3-5 key findings, and a confidence score.\"\n","    ),\n","    # REFACTORED: Provide a clear, human-readable instruction for the LLM.\n","    expected_output=\"A JSON object conforming to the ResearchSummary schema, including a title, key_findings, and confidence_score.\",\n","    agent=researcher,\n","    # The corrected guardrail function is applied here.\n","    guardrail=validate_research_summary,\n","    # REFACTORED: Use `output_pydantic` for automatic parsing into the specified model.\n","    # This replaces the old `output_json` parameter.\n","    output_pydantic=ResearchSummary,\n","    output_file='climate_research_summary.json'\n",")\n","\n","# Task 2: Data Processing Task\n","data_processing_task = Task(\n","    description=(\n","        \"Analyze the research summary from the previous task and report on its structure. \"\n","        \"Your input will be the JSON from the researcher. \"\n","        \"Confirm that it contains a title, at least three findings, and a confidence score.\"\n","    ),\n","    expected_output=\"A brief confirmation report on the data's quality.\",\n","    agent=data_analyst,\n","    context=[research_task] # This task uses the output of the research task as context.\n",")\n","\n","# --- 6. Crew Setup ---\n","crew = Crew(\n","    agents=[researcher, data_analyst],\n","    tasks=[research_task, data_processing_task],\n","    process=Process.sequential,\n","    verbose=True,\n",")\n","\n","# --- 7. Execution ---\n","if __name__ == \"__main__\":\n","    user_query = \"Please research climate change impacts on coastal cities.\"\n","    is_clean, message = moderate_input(user_query)\n","\n","    if is_clean:\n","        logging.info(\"Input is clean. Starting crew execution...\")\n","\n","        # The `kickoff` method will now return the output of the final task.\n","        # Since the final task's agent (data_analyst) doesn't have a Pydantic\n","        # output defined, this will likely be a string.\n","        result = crew.kickoff()\n","\n","        print(\"\\n--- Crew Execution Finished ---\")\n","\n","        # The final result is the output of the last task in the sequence.\n","        print(\"\\nFinal Result from Crew:\")\n","        print(result)\n","\n","        # The structured output from the first task is saved to the file.\n","        print(f\"\\nStructured output from the research task has been saved to: {research_task.output_file}\")\n","        # You can also access the structured output directly from the task object after execution:\n","        if research_task.output:\n","             print(\"\\nAccessing structured output from the research task object:\")\n","             # The .output attribute holds the Pydantic object\n","             print(research_task.output.model_dump_json(indent=2))\n","\n","    else:\n","        logging.error(f\"Input rejected by moderation: {message}\")\n","        print(f\"\\nCannot proceed: {message}\")"]}]}