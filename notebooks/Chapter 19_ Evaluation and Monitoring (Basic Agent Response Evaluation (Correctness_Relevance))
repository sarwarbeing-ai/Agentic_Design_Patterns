{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1-eAjTlNP1jq1bcRNhpw39hiYsuKV-8Cd","timestamp":1749136476078}],"authorship_tag":"ABX9TyMxcBMosbhsiI242tz4Xkm7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QMUWyDSjx-VH"},"outputs":[],"source":["def evaluate_response_accuracy(agent_output: str, expected_output: str) -> float:\n","    \"\"\"Calculates a simple accuracy score for agent responses.\"\"\"\n","    # This is a very basic exact match; real-world would use more sophisticated metrics\n","    return 1.0 if agent_output.strip().lower() == expected_output.strip().lower() else 0.0\n","\n","# Example usage\n","agent_response = \"The capital of France is Paris.\"\n","ground_truth = \"Paris is the capital of France.\"\n","score = evaluate_response_accuracy(agent_response, ground_truth)\n","print(f\"Response accuracy: {score}\")\n","\n","\n","import time\n","\n","def timed_agent_action(agent_function, *args, **kwargs):\n","    \"\"\"Measures the execution time of an agent's function.\"\"\"\n","    start_time = time.perf_counter()\n","    result = agent_function(*args, **kwargs)\n","    end_time = time.perf_counter()\n","    latency_ms = (end_time - start_time) * 1000\n","    print(f\"Action '{agent_function.__name__}' took {latency_ms:.2f} ms\")\n","    return result, latency_ms\n","\n","# Example usage with a dummy agent function\n","def simulated_tool_call(query):\n","    time.sleep(0.15) # Simulate some work\n","    return f\"Result for {query}\"\n","\n","result, latency = timed_agent_action(simulated_tool_call, \"get weather\")\n","print(f\"Tool call result: {result}\")\n","\n","# This is conceptual as actual token counting depends on the LLM API\n","class LLMInteractionMonitor:\n","    def __init__(self):\n","        self.total_input_tokens = 0\n","        self.total_output_tokens = 0\n","\n","    def record_interaction(self, prompt: str, response: str):\n","        # In a real scenario, use LLM API's token counter or a tokenizer\n","        input_tokens = len(prompt.split()) # Placeholder\n","        output_tokens = len(response.split()) # Placeholder\n","        self.total_input_tokens += input_tokens\n","        self.total_output_tokens += output_tokens\n","        print(f\"Recorded interaction: Input tokens={input_tokens}, Output tokens={output_tokens}\")\n","\n","    def get_total_tokens(self):\n","        return self.total_input_tokens, self.total_output_tokens\n","\n","# Example usage\n","monitor = LLMInteractionMonitor()\n","monitor.record_interaction(\"What is the capital of France?\", \"The capital of France is Paris.\")\n","monitor.record_interaction(\"Tell me a joke.\", \"Why don't scientists trust atoms? Because they make up everything!\")\n","input_t, output_t = monitor.get_total_tokens()\n","print(f\"Total input tokens: {input_t}, Total output tokens: {output_t}\")"]}]}