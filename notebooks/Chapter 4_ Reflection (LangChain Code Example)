{"cells":[{"cell_type":"code","source":["import os\n","import sys\n","import asyncio\n","from langchain_openai import ChatOpenAI\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","\n","# --- Configuration ---\n","# Ensure your API key environment variable is set (e.g., OPENAI_API_KEY)\n","try:\n","    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n","    print(f\"Language model initialized: {llm.model_name}\")\n","except Exception as e:\n","    print(f\"Error initializing language model: {e}\", file=sys.stderr)\n","    print(\"Please ensure your OPENAI_API_KEY is set correctly.\", file=sys.stderr)\n","    sys.exit(1) # Exit if the LLM cannot be initialized\n","\n","\n","# --- Define Chain Components ---\n","\n","# 1. Initial Generation: Creates the first draft of the product description.\n","# The input to this chain will be a dictionary, so we update the prompt template.\n","generation_chain = (\n","    ChatPromptTemplate.from_messages([\n","        (\"system\", \"Write a short, simple product description for a new smart coffee mug.\"),\n","        (\"user\", \"{product_details}\")\n","    ])\n","    | llm\n","    | StrOutputParser()\n",")\n","\n","# 2. Critique: Evaluates the generated description and provides feedback.\n","critique_chain = (\n","    ChatPromptTemplate.from_messages([\n","        (\"system\", \"\"\"Critique the following product description based on clarity, conciseness, and appeal.\n","        Provide specific suggestions for improvement.\"\"\"),\n","        # This will receive 'initial_description' from the previous step.\n","        (\"user\", \"Product Description to Critique:\\n{initial_description}\")\n","    ])\n","    | llm\n","    | StrOutputParser()\n",")\n","\n","# 3. Refinement: Rewrites the description based on the original details and the critique.\n","refinement_chain = (\n","    ChatPromptTemplate.from_messages([\n","        (\"system\", \"\"\"Based on the original product details and the following critique,\n","        rewrite the product description to be more effective.\n","\n","        Original Product Details: {product_details}\n","        Critique: {critique}\n","\n","        Refined Product Description:\"\"\"),\n","        (\"user\", \"\") # User input is empty as the context is provided in the system message\n","    ])\n","    | llm\n","    | StrOutputParser()\n",")\n","\n","\n","# --- Build the Full Reflection Chain (Refactored) ---\n","# This chain is structured to be more readable and linear.\n","full_reflection_chain = (\n","    RunnablePassthrough.assign(\n","        initial_description=generation_chain\n","    )\n","    | RunnablePassthrough.assign(\n","        critique=critique_chain\n","    )\n","    | refinement_chain\n",")\n","\n","\n","# --- Run the Chain ---\n","async def run_reflection_example(product_details: str):\n","    \"\"\"Runs the LangChain reflection example with product details.\"\"\"\n","    print(f\"\\n--- Running Reflection Example for Product: '{product_details}' ---\")\n","    try:\n","        # The chain now expects a dictionary as input from the start.\n","        final_refined_description = await full_reflection_chain.ainvoke(\n","            {\"product_details\": product_details}\n","        )\n","        print(\"\\n--- Final Refined Product Description ---\")\n","        print(final_refined_description)\n","    except Exception as e:\n","        print(f\"\\nAn error occurred during chain execution: {e}\")\n","\n","if __name__ == \"__main__\":\n","    test_product_details = \"A mug that keeps coffee hot and can be controlled by a smartphone app.\"\n","    asyncio.run(run_reflection_example(test_product_details))"],"outputs":[],"execution_count":null,"metadata":{"id":"3NBB8hsfc7iJ"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}